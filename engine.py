# type: ignore
# !/usr/bin/env python3
import math
import sys
import time
from typing import Iterable, Optional, List
from torch import Tensor

import torch
import torch.nn.functional as F
import util.misc as utils
from util.misc import NestedTensor, nested_tensor_from_tensor_list
from util.box_ops import box_cxcywh_to_xyxy, generalized_box_iou
import numpy as np
from pathlib import Path
import json
from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix
from collections import Counter, defaultdict, deque
import datetime
import os
import subprocess
import torchvision

# ===== ç»Ÿä¸€é˜ˆå€¼è®¾ç½® =====
IOU_THRESHOLD = 0.5  # IoUé˜ˆå€¼ï¼šç”¨äºåˆ¤æ–­é¢„æµ‹æ¡†ä¸çœŸå®æ¡†æ˜¯å¦åŒ¹é…
EVAL_CONFIDENCE_THRESHOLD = 0.3  # è¯„ä¼°ç½®ä¿¡åº¦é˜ˆå€¼
# è¯„ä¼°é˜¶æ®µçš„ä¸€ç»´NMSä¸æ¸©åº¦ç¼©æ”¾
NMS_IOU_THRESHOLD = 0.4  # ä¸€ç»´NMSçš„IoUé˜ˆå€¼ï¼ˆç±»å†…å»é‡ï¼‰
EVAL_TEMPERATURE = 1.0   # ä½ç½®æ¦‚ç‡æ¸©åº¦ç¼©æ”¾ï¼ˆsoftmax æ¸©åº¦ï¼‰

# é‡è¦è¯´æ˜ï¼š
# 1. ç±»åˆ«ä¸€è‡´æ€§ï¼šä¸¥æ ¼è¦æ±‚é¢„æµ‹ç±»åˆ«=GTç±»åˆ«æ‰èƒ½åŒ¹é…
# 2. èƒŒæ™¯ç±»æ’é™¤ï¼šèƒŒæ™¯ç±»å®Œå…¨æ’é™¤åœ¨TPåˆ¤æ–­å¤–ï¼Œä»ä¸å‚ä¸è¯„ä¼°
# 3. ç½®ä¿¡åº¦å¤„ç†ï¼šæ ‡å‡†mAPä¸ä½¿ç”¨å›ºå®šç½®ä¿¡åº¦é˜ˆå€¼é¢„è¿‡æ»¤ï¼Œç›´æ¥è®¡ç®—Precision-Recallæ›²çº¿
# 4. è¯„ä¼°è¿‡æ»¤ï¼šä½¿ç”¨EVAL_CONFIDENCE_THRESHOLDè¿‡æ»¤ä½è´¨é‡é¢„æµ‹æ¡†

# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved
"""
è®­ç»ƒå’Œè¯„ä¼°å¼•æ“æ¨¡å—
æä¾›DETRæ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°åŠŸèƒ½

è¯¥æ¨¡å—åŒ…å«ä¸¤ä¸ªä¸»è¦å‡½æ•°ï¼š
1. train_one_epoch: è®­ç»ƒä¸€ä¸ªepoch
2. evaluate: è¯„ä¼°æ¨¡å‹æ€§èƒ½

ä¸»è¦åŠŸèƒ½ï¼š
- è®­ç»ƒå¾ªç¯ç®¡ç†
- æŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­
- æ€§èƒ½æŒ‡æ ‡è®¡ç®—
- æ¨¡å‹è¯„ä¼°å’Œç»“æœè¾“å‡º
"""


def train_one_epoch(model: torch.nn.Module,
                    criterion: torch.nn.Module,
                    data_loader: Iterable,
                    optimizer: torch.optim.Optimizer,
                    device: torch.device,
                    epoch: int,
                    max_norm: float = 0,
                    lr_scheduler=None,
                    fold=None):
    """
    è®­ç»ƒä¸€ä¸ªepoch
    """
    model.train()
    criterion.train()
    metric_logger = utils.MetricLogger(delimiter="  ")
    metric_logger.add_meter('lr',
                            utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))
    metric_logger.add_meter('class_error',
                            utils.SmoothedValue(window_size=1, fmt='{value:.2f}'))
    header = f'Epoch: [{epoch}]'
    print_freq = 20

    # ===== è®­ç»ƒå¾ªç¯ =====
    for samples, targets in metric_logger.log_every(data_loader, print_freq, header):
        # ===== 1. æ•°æ®é¢„å¤„ç† =====
        samples = samples.to(device)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        # ===== 2. å‰å‘ä¼ æ’­ =====
        outputs = model(samples)
        loss_dict = criterion(outputs, targets)
        weight_dict = criterion.weight_dict
        losses = sum(loss_dict[k] * weight_dict[k]
                     for k in loss_dict.keys() if k in weight_dict)

        # ===== 3. åå‘ä¼ æ’­ =====
        loss_value = losses.item()
        if not math.isfinite(loss_value):
            print("Loss is {}, stopping training".format(loss_value))
            print(loss_dict)
            sys.exit(1)

        optimizer.zero_grad()
        losses.backward()

        # ===== 4. æ¢¯åº¦è£å‰ª =====
        if max_norm > 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)

        # ===== 5. ä¼˜åŒ–å™¨æ­¥è¿› =====
        optimizer.step()

        # ===== 6. æŒ‡æ ‡æ›´æ–° =====
        metric_logger.update(loss=loss_value, **
                             {k: v.item() for k, v in loss_dict.items()})
        metric_logger.update(class_error=loss_dict['class_error'])
        metric_logger.update(lr=optimizer.param_groups[0]["lr"])

    # ===== 7. è¿”å›è®­ç»ƒæŒ‡æ ‡ =====
    metric_logger.synchronize_between_processes()
    print("Averaged stats:", metric_logger)

    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}


def compute_1d_iou(box1, box2):
    """
    è®¡ç®—1Dåºåˆ—ä¸Šçš„IoU
    box1, box2: [x0, x1] æ ¼å¼ï¼Œè¡¨ç¤ºèµ·å§‹å’Œç»“æŸä½ç½®
    """
    x0_1, x1_1 = box1
    x0_2, x1_2 = box2

    # è®¡ç®—äº¤é›†
    x0_i = max(x0_1, x0_2)
    x1_i = min(x1_1, x1_2)
    intersection = max(0, x1_i - x0_i)

    # è®¡ç®—å¹¶é›†
    x0_u = min(x0_1, x0_2)
    x1_u = max(x1_1, x1_2)
    union = x1_u - x0_u

    # è®¡ç®—IoU
    iou = intersection / union if union > 0 else 0.0
    return iou


def nms_1d_greedy(boxes, scores, iou_thresh):
    """
    å¯¹1DåŒºé—´æ‰§è¡Œè´ªå¿ƒNMSã€‚
    boxes: Tensor [N, 2] ï¼ˆå·²åœ¨åŒä¸€å°ºåº¦ï¼‰
    scores: Tensor [N]
    è¿”å›: ä¿ç•™çš„ç´¢å¼•ï¼ˆæŒ‰scoreé™åºï¼‰
    """
    if boxes.numel() == 0:
        return []
    order = torch.argsort(scores, descending=True)
    keep = []
    suppressed = torch.zeros(len(order), dtype=torch.bool)
    for i in range(len(order)):
        if suppressed[i]:
            continue
        idx_i = order[i]
        keep.append(idx_i.item())
        bi = boxes[idx_i]
        for j in range(i + 1, len(order)):
            if suppressed[j]:
                continue
            idx_j = order[j]
            bj = boxes[idx_j]
            iou = compute_1d_iou(bi.tolist(), bj.tolist())
            if iou >= iou_thresh:
                suppressed[j] = True
    return keep


@torch.no_grad()
def evaluate(model: torch.nn.Module,
             criterion: torch.nn.Module,
             postprocessors: dict,
             data_loader: Iterable,
             device: torch.device,
             log_dir: str,
             epoch: int,
             fold: int = None,
             class_mapping: dict = None,
             localization_only: bool = False,
             sample_level_fp: bool = False,
             binary_mode: bool = False,
             bg_class_index: int = None):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½

    è¯„ä¼°æµç¨‹ï¼š
    1. æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    2. å¯¹æ¯ä¸ªæ‰¹æ¬¡è¿›è¡Œå‰å‘ä¼ æ’­
    3. åå¤„ç†é¢„æµ‹ç»“æœ
    4. ä½¿ç”¨è´ªå¿ƒåŒ¹é…è®¡ç®—mAPæŒ‡æ ‡
    5. ä¿å­˜ç»“æœï¼ˆå¦‚æœæŒ‡å®šè¾“å‡ºç›®å½•ï¼‰

    Args:
        model: DETRæ¨¡å‹
        criterion: æŸå¤±å‡½æ•°
        postprocessors: åå¤„ç†å™¨
        data_loader: æ•°æ®åŠ è½½å™¨
        device: è®¡ç®—è®¾å¤‡
        log_dir: è¾“å‡ºç›®å½•
        epoch: å½“å‰epochæ•°
        fold: å½“å‰foldæ•°
        class_mapping: ç±»åˆ«æ˜ å°„å­—å…¸
        localization_only: æ˜¯å¦åªè®¡ç®—å®šä½ä»»åŠ¡
        sample_level_fp: æ˜¯å¦æŒ‰æ ·æœ¬çº§åˆ«è®¡ç®—å‡é˜³æ€§ï¼ˆæ¨èç”¨äºè´Ÿæ ·æœ¬å¤„ç†ï¼‰
        binary_mode: æ˜¯å¦ä½¿ç”¨äºŒåˆ†ç±»æ¨¡å¼
        bg_class_index: èƒŒæ™¯ç±»ç´¢å¼•ï¼ˆä»…åœ¨äºŒåˆ†ç±»æ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰

    Returns:
        dict: åŒ…å«è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
    """
    model.eval()
    criterion.eval()
    metric_logger = utils.MetricLogger(delimiter="  ")
    # ç§»é™¤class_error meterï¼Œå› ä¸ºæˆ‘ä»¬åœ¨è¯„ä¼°æ—¶ä¸ä½¿ç”¨è®­ç»ƒæ—¶çš„class_error
    # metric_logger.add_meter('class_error',
    #                         utils.SmoothedValue(window_size=1, fmt='{value:.2f}'))

    header = 'Test:'

    # åœ¨evaluateå‡½æ•°å¼€å¤´ï¼Œå…¼å®¹å•GPUå’Œå¤šGPUç¯å¢ƒè·å–num_classes
    if hasattr(model, 'module'):
        # å¤šGPUç¯å¢ƒ (DataParallel/DistributedDataParallel)
        num_classes = model.module.class_embed.out_features
    else:
        # å•GPUç¯å¢ƒ
        num_classes = model.class_embed.out_features

    binary_mode = bool(binary_mode)
    if bg_class_index is None:
        bg_class_index = num_classes - 1

    detr_bg_class = bg_class_index

    # ç°åœ¨ç±»åˆ«æ˜ å°„ä¿è¯no-objectåœ¨æœ€åï¼ŒDETRèƒŒæ™¯ç±»å’Œæ•°æ®é›†no-objectç±»ç´¢å¼•ä¸€è‡´
    background_classes = [detr_bg_class]
    print(f"DETRèƒŒæ™¯ç±»ç´¢å¼•: {detr_bg_class} (no-object)")
    print(f"èƒŒæ™¯ç±»åˆ—è¡¨: {background_classes}")
    print(f"æ¨¡å‹ç±»åˆ«æ€»æ•°: {num_classes}")

    # åˆå§‹åŒ–æ ‡ç­¾æ”¶é›†åˆ—è¡¨ï¼ˆåªä¿ç•™æœ€ç»ˆè¯„ä¼°ç›¸å…³ï¼‰
    collected_pred_labels = []
    collected_true_labels = []
    collected_pred_probs = []
    collected_pred_labels_bin = []
    collected_true_labels_bin = []
    collected_pred_probs_bin = []
    collected_pred_local = []
    # æ ·æœ¬çº§ï¼ˆäºŒåˆ†ç±»ï¼šæ˜¯å¦å­˜åœ¨BGCï¼‰
    collected_sample_labels = []  # 0/1
    collected_sample_scores = []  # è¿ç»­åˆ†æ•°ï¼ˆç”¨äºAUCï¼‰
    collected_true_local = []

    # å…¨å±€åˆ†å¸ƒç»Ÿè®¡æ”¶é›†å™¨
    iou_distribution = []  # æ”¶é›†æ‰€æœ‰é¢„æµ‹æ¡†çš„æœ€å¤§IoU
    class_distribution = defaultdict(int)  # æ”¶é›†é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ
    bg_pred_count = 0  # èƒŒæ™¯ç±»é¢„æµ‹è®¡æ•°
    non_bg_pred_count = 0  # éèƒŒæ™¯ç±»é¢„æµ‹è®¡æ•°

    # çœŸå®æ¡†ä¿¡æ¯æ”¶é›†
    gt_class_distribution = defaultdict(int)  # æ”¶é›†çœŸå®ç±»åˆ«åˆ†å¸ƒ
    gt_bg_count = 0  # çœŸå®èƒŒæ™¯ç±»è®¡æ•°
    gt_non_bg_count = 0  # çœŸå®éèƒŒæ™¯ç±»è®¡æ•°

    # ===== è´ªå¿ƒåŒ¹é…mAPè®¡ç®—æ‰€éœ€çš„æ•°æ®ç»“æ„ =====
    # ä¸ºæ¯ä¸ªç±»åˆ«æ”¶é›†é¢„æµ‹å’ŒçœŸå®æ¡†ä¿¡æ¯
    # {class_id: [(score, pred_box, image_id, matched)]}
    all_predictions = defaultdict(list)
    all_targets = defaultdict(int)  # {class_id: total_gt_count}
    # {class_id: {image_id: [gt_boxes]}}
    all_gt_boxes_by_image = defaultdict(lambda: defaultdict(list))

    image_id = 0  # å›¾åƒç´¢å¼•

    # ç»Ÿè®¡å˜é‡
    total_predicted_boxes = 0
    total_target_boxes = 0
    total_correct_boxes = 0
    total_false_positive = 0
    total_false_negative = 0
    num_positive_samples = 0

    # ğŸ”¥ è°ƒè¯•ï¼šFPæ¥æºç»Ÿè®¡
    fp_from_negative_samples = 0
    fp_from_positive_samples = 0

    # è°ƒè¯•å˜é‡
    debug_positive_images = 0
    debug_negative_images = 0
    debug_pred_boxes_collected = 0

    # ===== æ–°å¢ï¼šè¯¦ç»†ç±»åˆ«åŒ¹é…åˆ†æ =====
    class_match_analysis = defaultdict(lambda: {
        'pred_count': 0,  # è¯¥ç±»åˆ«çš„é¢„æµ‹æ¡†æ•°é‡
        'gt_count': 0,  # è¯¥ç±»åˆ«çš„çœŸå®æ¡†æ•°é‡
        'matched_count': 0,  # æˆåŠŸåŒ¹é…çš„æ•°é‡
        'high_iou_count': 0,  # é«˜IoUä½†ç±»åˆ«ä¸åŒ¹é…çš„æ•°é‡
        'low_iou_count': 0,  # ä½IoUçš„æ•°é‡
    })

    # è·¨ç±»åˆ«é«˜IoUç»Ÿè®¡
    # {pred_class: {gt_class: count}}
    cross_class_high_iou = defaultdict(lambda: defaultdict(int))

    for samples, targets in metric_logger.log_every(data_loader, 10, header):
        samples = samples.to(device)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        outputs = model(samples)
        loss_dict = criterion(outputs, targets)
        weight_dict = criterion.weight_dict

        # è®°å½•æŸå¤±
        loss_dict_reduced = utils.reduce_dict(loss_dict)
        loss_dict_reduced_scaled = {k: v * weight_dict[k]
                                    for k, v in loss_dict_reduced.items() if k in weight_dict}
        loss_dict_reduced_unscaled = {f'{k}_unscaled': v
                                      for k, v in loss_dict_reduced.items()}
        # åœ¨è¯„ä¼°é˜¶æ®µï¼Œæˆ‘ä»¬ä¸åº”è¯¥ä½¿ç”¨è®­ç»ƒæ—¶çš„class_error
        # è€Œæ˜¯åº”è¯¥è®¡ç®—è¯„ä¼°æ—¶çš„åˆ†ç±»å‡†ç¡®ç‡
        update_dict = {
            'loss': sum(loss_dict_reduced_scaled.values()) if loss_dict_reduced_scaled else 0.0
        }
        update_dict.update(loss_dict_reduced_scaled)
        update_dict.update(loss_dict_reduced_unscaled)
        metric_logger.update(**update_dict)

        # ===== è´ªå¿ƒåŒ¹é…mAPè®¡ç®— =====
        for i in range(len(outputs['pred_boxes'])):
            # è·å–å½“å‰æ ·æœ¬çš„CDSåµŒå…¥ï¼ˆç”¨äºç²¾ç»†åŒ–CDSçº§åˆ«é¢„æµ‹ï¼‰
            # samples æ˜¯ NestedTensorï¼Œéœ€è¦é€šè¿‡ .tensors å±æ€§è®¿é—®
            sample_embedding = samples.tensors[i]  # [seq_len, embed_dim]
            seq_len = sample_embedding.shape[0]

            all_pred_boxes = outputs['pred_boxes'][i].cpu()
            all_pred_logits = outputs['pred_logits'][i].cpu()
            all_tgt_boxes = targets[i]['boxes'].cpu()
            all_tgt_labels = targets[i]['labels'].cpu()

            if binary_mode:
                bg_logits = all_pred_logits[..., detr_bg_class].unsqueeze(-1)
                if all_pred_logits.shape[-1] > 1:
                    pos_logits = torch.logsumexp(all_pred_logits[..., :detr_bg_class], dim=-1, keepdim=True)
                else:
                    pos_logits = torch.zeros_like(bg_logits)
                logits_binary = torch.cat([pos_logits, bg_logits], dim=-1)
                probs_binary = logits_binary.softmax(-1)
                labels_binary = logits_binary.argmax(-1)
                scores_binary = probs_binary[..., 0]

                tgt_binary = all_tgt_labels.clone()
                tgt_binary[tgt_binary != detr_bg_class] = 0
                tgt_binary[tgt_binary == detr_bg_class] = 1

                all_pred_labels = labels_binary
                all_pred_scores = scores_binary
            else:
                all_pred_labels = all_pred_logits.argmax(-1)
                all_pred_scores = all_pred_logits.softmax(-1).max(-1)[0]

            # ğŸ”¥ ä¿®å¤ï¼šç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„çœŸå®æ¡†æ•°é‡
            for gt_label in all_tgt_labels:
                gt_label_item = gt_label.item() if hasattr(gt_label, 'item') else gt_label
                if gt_label_item not in background_classes:
                    class_match_analysis[gt_label_item]['gt_count'] += 1

            # ===== è°ƒè¯•ï¼šåˆ†æé¢„æµ‹åˆ†å¸ƒ =====
            if image_id == 0:  # åªåœ¨ç¬¬ä¸€å¼ å›¾åƒæ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
                # [num_queries, num_classes]
                pred_probs = all_pred_logits.softmax(-1)
                print(f"\n===== é¢„æµ‹åˆ†å¸ƒè°ƒè¯• (ç¬¬ä¸€å¼ å›¾åƒ) =====")
                print(f"é¢„æµ‹logits shape: {all_pred_logits.shape}")
                print(f"é¢„æµ‹æ¦‚ç‡ shape: {pred_probs.shape}")

                # åˆ†ælogitsçš„åŸå§‹å€¼
                print(f"Logitsç»Ÿè®¡:")
                print(f"  - æœ€å°å€¼: {all_pred_logits.min().item():.3f}")
                print(f"  - æœ€å¤§å€¼: {all_pred_logits.max().item():.3f}")
                print(f"  - å‡å€¼: {all_pred_logits.mean().item():.3f}")
                print(f"  - æ ‡å‡†å·®: {all_pred_logits.std().item():.3f}")

                # æ‰“å°queryçš„æ¦‚ç‡åˆ†å¸ƒ
                print(f"å‰5ä¸ªqueryçš„ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ:")
                for q in range(min(5, len(pred_probs))):
                    probs = pred_probs[q]
                    logits = all_pred_logits[q]
                    pred_label = all_pred_labels[q]
                    max_prob = probs.max()
                    if hasattr(max_prob, 'item'):
                        max_prob = max_prob.item()
                    pred_label_val = pred_label
                    if hasattr(pred_label_val, 'item'):
                        pred_label_val = pred_label_val.item()
                    print(
                        f"  Query {q}: é¢„æµ‹ç±»åˆ«={pred_label_val}, æœ€å¤§æ¦‚ç‡={max_prob:.4f}")
                    print(
                        f"    Logits: {[f'{l:.3f}' for l in logits.tolist()]}")
                    print(
                        f"    Probs:  {[f'{p:.3f}' for p in probs.tolist()]}")

                # ç»Ÿè®¡å„ç±»åˆ«çš„å¹³å‡é¢„æµ‹æ¦‚ç‡
                mean_probs = pred_probs.mean(dim=0)
                print(
                    f"å„ç±»åˆ«å¹³å‡é¢„æµ‹æ¦‚ç‡: {[f'{p:.4f}' for p in mean_probs.tolist()]}")

                # åˆ†ææ˜¯å¦æ‰€æœ‰queryéƒ½é¢„æµ‹åŒä¸€ä¸ªç±»åˆ«
                unique_labels, counts = torch.unique(
                    all_pred_labels, return_counts=True)
                print(f"å½“å‰å›¾åƒé¢„æµ‹æ ‡ç­¾åˆ†å¸ƒ:")
                for label, count in zip(unique_labels, counts):
                    label_val = label
                    if hasattr(label_val, 'item'):
                        label_val = label_val.item()
                    count_val = count
                    if hasattr(count_val, 'item'):
                        count_val = count_val.item()
                    print(f"  ç±»åˆ« {label_val}: {count_val} ä¸ªé¢„æµ‹æ¡†")

                # æ£€æŸ¥åˆ†ç±»å¤´æƒé‡
                class_embed = model.module.class_embed if hasattr(
                    model, 'module') else model.class_embed
                print(
                    f"åˆ†ç±»å¤´åç½®å€¼: {[f'{b:.3f}' for b in class_embed.bias.tolist()]}")

                # ===== æ–°å¢ï¼šæ‰“å°é¢„æµ‹æ¡†ä½ç½®å’ŒçœŸå®ä½ç½®å¯¹æ¯” =====
                print(f"\n===== é¢„æµ‹æ¡†ä½ç½®å’ŒçœŸå®ä½ç½®å¯¹æ¯” =====")

                # è·å–åºåˆ—é•¿åº¦ç”¨äºåå½’ä¸€åŒ–
                seq_len = targets[i].get('size', 128)
                if isinstance(seq_len, torch.Tensor):
                    if seq_len.numel() == 1:
                        seq_len = seq_len
                        if hasattr(seq_len, 'item'):
                            seq_len = seq_len.item()
                    else:
                        # å¦‚æœseq_lenæœ‰å¤šä¸ªå…ƒç´ ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                        seq_len_val = seq_len[0]
                        if hasattr(seq_len_val, 'item'):
                            seq_len_val = seq_len_val.item()
                        seq_len = seq_len_val

                # æ‰“å°å‰3ä¸ªqueryçš„é¢„æµ‹æ¡†ä½ç½®
                print(f"å‰3ä¸ªqueryçš„é¢„æµ‹æ¡†ä½ç½®:")
                for q in range(min(3, len(all_pred_boxes))):
                    pred_box = all_pred_boxes[q]
                    pred_label = all_pred_labels[q]
                    if hasattr(pred_label, 'item'):
                        pred_label = pred_label.item()
                    pred_score = all_pred_scores[q]
                    if hasattr(pred_score, 'item'):
                        pred_score = pred_score.item()

                    # åå½’ä¸€åŒ–åæ ‡
                    start_pos = int(pred_box[0].item() * seq_len)
                    end_pos = int(pred_box[1].item() * seq_len)

                    print(
                        f"  Query {q}: é¢„æµ‹ç±»åˆ«={pred_label}, ç½®ä¿¡åº¦={pred_score:.4f}")
                    print(
                        f"    é¢„æµ‹ä½ç½®: [{pred_box[0].item():.3f}, {pred_box[1].item():.3f}] -> CDS[{start_pos}, {end_pos}]")

                # æ‰“å°æ‰€æœ‰çœŸå®æ¡†ä½ç½®
                print(f"\nçœŸå®æ¡†ä½ç½®:")
                if len(all_tgt_boxes) == 0:
                    print("  æ— çœŸå®æ¡†")
                else:
                    for gt_idx in range(len(all_tgt_boxes)):
                        gt_box = all_tgt_boxes[gt_idx]
                        gt_label = all_tgt_labels[gt_idx]
                        if hasattr(gt_label, 'item'):
                            gt_label = gt_label.item()

                        # åå½’ä¸€åŒ–åæ ‡
                        start_pos = int(gt_box[0].item() * seq_len)
                        end_pos = int(gt_box[1].item() * seq_len)

                        print(f"  çœŸå®æ¡† {gt_idx}: ç±»åˆ«={gt_label}")
                        print(
                            f"    çœŸå®ä½ç½®: [{gt_box[0].item():.3f}, {gt_box[1].item():.3f}] -> CDS[{start_pos}, {end_pos}]")

                # è®¡ç®—å¹¶æ‰“å°IoUå¯¹æ¯”
                print(f"\nIoUå¯¹æ¯”:")
                for q in range(min(3, len(all_pred_boxes))):
                    pred_box = all_pred_boxes[q]
                    pred_label = all_pred_labels[q].item()

                    best_iou = 0.0
                    best_gt_idx = -1

                    for gt_idx in range(len(all_tgt_boxes)):
                        gt_box = all_tgt_boxes[gt_idx]
                        gt_label = all_tgt_labels[gt_idx]
                        if hasattr(gt_label, 'item'):
                            gt_label = gt_label.item()

                        # åªè®¡ç®—åŒç±»åˆ«çš„IoU
                        if gt_label == pred_label:
                            iou = compute_1d_iou(
                                pred_box.tolist(), gt_box.tolist())
                            if iou > best_iou:
                                best_iou = iou
                                best_gt_idx = gt_idx

                    if best_gt_idx >= 0:
                        gt_box = all_tgt_boxes[best_gt_idx]
                        print(
                            f"  Query {q} ä¸çœŸå®æ¡† {best_gt_idx} (åŒç±»): IoU = {best_iou:.4f}")
                    else:
                        print(f"  Query {q}: æ— åŒç±»çœŸå®æ¡†åŒ¹é…")

                print("=" * 40)

            # åˆ¤æ–­æ˜¯å¦ä¸ºæ­£æ ·æœ¬å›¾åƒï¼ˆæœ‰éèƒŒæ™¯ç±»ç›®æ ‡ï¼‰
            if binary_mode:
                non_bg_gt_mask = [label == 0 for label in tgt_binary]
            else:
                non_bg_gt_mask = [label not in background_classes for label in all_tgt_labels]
            is_positive_image = any(non_bg_gt_mask)

            # æ ·æœ¬çº§åˆ†æ•°æ”¹ä¸ºå®šä½å£å¾„ï¼šåç»­æ ¹æ®"æ˜¯å¦å­˜åœ¨åŒ¹é…æˆåŠŸçš„é¢„æµ‹æ¡†"èšåˆ

            if is_positive_image:
                num_positive_samples += 1
                debug_positive_images += 1
            else:
                debug_negative_images += 1

            # ===== æŒ‰ç±»åˆ«è¿›è¡Œè´ªå¿ƒåŒ¹é… =====
            # ğŸ”¥ ä¿®æ”¹è¯´æ˜ï¼šå¯¹äºæ­£æ ·æœ¬å›¾åƒï¼Œåªå…³æ³¨åŒ¹é…åˆ°çš„é¢„æµ‹æ¡†
            # æœªåŒ¹é…çš„é¢„æµ‹æ¡†ä¸è®¡å…¥FPï¼Œé¿å…å‡é˜³æ€§è¿‡é«˜
            # 1. ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„çœŸå®æ¡†æ•°é‡å¹¶æ”¶é›†çœŸå®æ¡†ä¿¡æ¯
            for gt_idx, gt_label in enumerate(all_tgt_labels):
                gt_label = gt_label.item() if hasattr(gt_label, 'item') else gt_label
                gt_box = all_tgt_boxes[gt_idx]

                if gt_label not in background_classes:
                    all_targets[gt_label] += 1
                    total_target_boxes += 1
                    # æ”¶é›†è¯¥ç±»åˆ«çš„çœŸå®æ¡†åˆ°å¯¹åº”å›¾åƒ
                    all_gt_boxes_by_image[gt_label][image_id].append(gt_box)

                # æ”¶é›†çœŸå®æ¡†åˆ†å¸ƒç»Ÿè®¡
                gt_class_distribution[gt_label] += 1
                if gt_label in background_classes:
                    gt_bg_count += 1
                else:
                    gt_non_bg_count += 1

            # 2. æ”¶é›†æ¯ä¸ªç±»åˆ«çš„é¢„æµ‹æ¡†ï¼ˆæ·»åŠ ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ï¼‰
            for pred_idx in range(len(all_pred_boxes)):
                pred_label = all_pred_labels[pred_idx].item()
                pred_score = all_pred_scores[pred_idx].item()
                pred_box = all_pred_boxes[pred_idx]

                # æ”¶é›†é¢„æµ‹åˆ†å¸ƒç»Ÿè®¡
                class_distribution[pred_label] += 1
                if pred_label in background_classes:
                    bg_pred_count += 1
                else:
                    non_bg_pred_count += 1

                # ===== ç½®ä¿¡åº¦è¿‡æ»¤ï¼šåªæœ‰é«˜ç½®ä¿¡åº¦çš„éèƒŒæ™¯ç±»é¢„æµ‹æ¡†æ‰å‚ä¸è¯„ä¼° =====
                if (pred_label not in background_classes and
                        pred_score >= EVAL_CONFIDENCE_THRESHOLD):

                    total_predicted_boxes += 1  # ç»Ÿè®¡é€šè¿‡ç½®ä¿¡åº¦è¿‡æ»¤çš„é¢„æµ‹æ¡†
                    debug_pred_boxes_collected += 1

                    # è®¡ç®—è¯¥é¢„æµ‹æ¡†ä¸åŒç±»åˆ«çœŸå®æ¡†çš„æœ€å¤§IoUï¼ˆç”¨äºåˆ†å¸ƒç»Ÿè®¡ï¼‰
                    max_iou = 0.0
                    for gt_idx, gt_box in enumerate(all_tgt_boxes):
                        gt_label = all_tgt_labels[gt_idx]
                        if hasattr(gt_label, 'item'):
                            gt_label = gt_label.item()

                        # åªè®¡ç®—åŒç±»åˆ«çš„IoU
                        if gt_label == pred_label:
                            iou = compute_1d_iou(
                                pred_box.tolist(), gt_box.tolist())
                            if iou > max_iou:
                                max_iou = iou
                    iou_distribution.append(max_iou)

                    # æ·»åŠ åˆ°è¯¥ç±»åˆ«çš„é¢„æµ‹åˆ—è¡¨ä¸­ (score, pred_box, image_id, matched)
                    all_predictions[pred_label].append(
                        (pred_score, pred_box, image_id, False))

            # 3. å¯¹å½“å‰å›¾åƒè¿›è¡Œè´ªå¿ƒåŒ¹é…ï¼ˆç”¨äºä½ç½®å’Œåˆ†ç±»æŒ‡æ ‡æ”¶é›†ï¼‰
            if is_positive_image:
                # åˆ†ç±»ä¸å®šä½æŒ‡æ ‡æ”¶é›†åˆå§‹åŒ–
                image_pred_labels = []  # é¢„æµ‹ç±»åˆ«
                image_true_labels = []  # çœŸå®ç±»åˆ«
                image_pred_probs = []  # æ¦‚ç‡åˆ†å¸ƒ
                image_loc_labels = []  # å®šä½æ­£ç¡®æ ‡ç­¾
                image_loc_scores = []  # å®šä½ç½®ä¿¡åº¦

                # [num_queries, num_classes]
                pred_probs = all_pred_logits.softmax(-1)

                # å¯¹å½“å‰å›¾åƒè¿›è¡Œè´ªå¿ƒåŒ¹é…æ¥æ”¶é›†åˆ†ç±»å’Œå®šä½æŒ‡æ ‡
                num_queries = len(all_pred_boxes)
                true_labels = torch.full((num_queries,), background_classes[0])
                loc_correct = torch.zeros(num_queries)

                # åˆ›å»ºåŒ¹é…çŠ¶æ€
                gt_matched = [False] * len(all_tgt_boxes)
                pred_matched = [False] * num_queries  # æ–°å¢ï¼šè®°å½•é¢„æµ‹æ¡†æ˜¯å¦è¢«åŒ¹é…

                # æŒ‰ç½®ä¿¡åº¦æ’åºæ‰€æœ‰é¢„æµ‹æ¡†ï¼ˆä¸ä½¿ç”¨ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ï¼‰
                sorted_indices = torch.argsort(
                    all_pred_scores, descending=True)

                for pred_idx in sorted_indices:
                    pred_box = all_pred_boxes[pred_idx]
                    pred_label = all_pred_labels[pred_idx]
                    if hasattr(pred_label, 'item'):
                        pred_label = pred_label.item()
                    pred_score = all_pred_scores[pred_idx]
                    if hasattr(pred_score, 'item'):
                        pred_score = pred_score.item()

                    # ===== ç½®ä¿¡åº¦è¿‡æ»¤ï¼šåªå¤„ç†é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹æ¡† =====
                    if (pred_label not in background_classes and
                            pred_score < EVAL_CONFIDENCE_THRESHOLD):
                        continue  # è·³è¿‡ä½ç½®ä¿¡åº¦é¢„æµ‹æ¡†

                    best_iou = 0.0
                    best_gt_idx = -1
                    best_gt_label = -1

                    # ===== è¯¦ç»†åŒ¹é…åˆ†æï¼šæ£€æŸ¥ä¸æ‰€æœ‰GTæ¡†çš„IoU =====
                    for gt_idx in range(len(all_tgt_boxes)):
                        if gt_matched[gt_idx]:
                            continue

                        gt_label = all_tgt_labels[gt_idx]
                        if hasattr(gt_label, 'item'):
                            gt_label = gt_label.item()
                        gt_box = all_tgt_boxes[gt_idx]

                        iou = compute_1d_iou(
                            pred_box.tolist(), gt_box.tolist())

                        # è®°å½•æœ€ä½³IoUåŒ¹é…ï¼ˆä¸è€ƒè™‘ç±»åˆ«ï¼‰
                        if iou > best_iou:
                            best_iou = iou
                            best_gt_idx = gt_idx
                            best_gt_label = gt_label

                    # ===== ç»Ÿè®¡ç±»åˆ«åŒ¹é…åˆ†æ =====
                    if pred_label not in background_classes:
                        class_match_analysis[pred_label]['pred_count'] += 1

                        if best_iou >= IOU_THRESHOLD and best_gt_idx != -1:
                            if localization_only or pred_label == best_gt_label:
                                # å®šä½ä»»åŠ¡æ¨¡å¼ï¼šåªè€ƒè™‘IoUï¼Œä¸è€ƒè™‘ç±»åˆ«
                                # æˆ–è€…åŒç±»åˆ«ä¸”é«˜IoUï¼šæˆåŠŸåŒ¹é…
                                # ğŸ” åªæ‰“å°ç¬¬ä¸€å¯¹æˆåŠŸåŒ¹é…çš„ä¿¡æ¯
                                if total_correct_boxes == 0:  # ç¬¬ä¸€æ¬¡TPåŒ¹é…
                                    pred_class_name = class_mapping.get(
                                        pred_label, f"ç±»åˆ«{pred_label}") if class_mapping else f"ç±»åˆ«{pred_label}"
                                    gt_class_name = class_mapping.get(
                                        best_gt_label, f"ç±»åˆ«{best_gt_label}") if class_mapping else f"ç±»åˆ«{best_gt_label}"
                                    if localization_only:
                                        print(f"\nğŸ” å®šä½ä»»åŠ¡æˆåŠŸåŒ¹é…ç¤ºä¾‹:")
                                        print(
                                            f"  é¢„æµ‹æ¡†: {pred_class_name}, ä½ç½®[{pred_box[0].item():.3f}, {pred_box[1].item():.3f}]")
                                        print(
                                            f"  çœŸå®æ¡†: {gt_class_name}, ä½ç½®[{all_tgt_boxes[best_gt_idx][0].item():.3f}, {all_tgt_boxes[best_gt_idx][1].item():.3f}]")
                                        print(f"  IoU: {best_iou:.3f} (å¿½ç•¥ç±»åˆ«)")
                                    else:
                                        print(f"\nğŸ” æˆåŠŸåŒ¹é…ç¤ºä¾‹:")
                                        print(
                                            f"  é¢„æµ‹æ¡†: {pred_class_name}, ä½ç½®[{pred_box[0].item():.3f}, {pred_box[1].item():.3f}]")
                                        print(
                                            f"  çœŸå®æ¡†: {gt_class_name}, ä½ç½®[{all_tgt_boxes[best_gt_idx][0].item():.3f}, {all_tgt_boxes[best_gt_idx][1].item():.3f}]")
                                        print(f"  IoU: {best_iou:.3f}")

                                class_match_analysis[pred_label]['matched_count'] += 1
                                gt_matched[best_gt_idx] = True
                                pred_matched[pred_idx] = True  # æ ‡è®°é¢„æµ‹æ¡†å·²åŒ¹é…
                                true_labels[pred_idx] = all_tgt_labels[best_gt_idx]
                                loc_correct[pred_idx] = 1
                                total_correct_boxes += 1
                            else:
                                # ä¸åŒç±»åˆ«ä½†é«˜IoUï¼šè®°å½•è·¨ç±»åˆ«åŒ¹é…
                                class_match_analysis[pred_label]['high_iou_count'] += 1
                                cross_class_high_iou[pred_label][best_gt_label] += 1
                                # åœ¨å®šä½ä»»åŠ¡æ¨¡å¼ä¸‹ï¼Œé«˜IoUä½†ç±»åˆ«ä¸åŒ¹é…ä¹Ÿç®—ä½œå‡é˜³æ€§
                                if not localization_only:
                                    total_false_positive += 1
                                    fp_from_positive_samples += 1
                        else:
                            # ä½IoUï¼šè®°å½•ä½IoUæƒ…å†µï¼Œä½†ä¸å¢åŠ FPï¼ˆåªè€ƒè™‘åŒ¹é…çš„æ¡†ï¼‰
                            class_match_analysis[pred_label]['low_iou_count'] += 1
                            # ğŸ”¥ ä¿®æ”¹ï¼šå¯¹äºæ­£æ ·æœ¬ï¼ŒæœªåŒ¹é…çš„é¢„æµ‹æ¡†ä¸è®¡å…¥FP
                            # ç§»é™¤è¿™è¡Œï¼štotal_false_positive += 1

                # ç»Ÿè®¡æœªåŒ¹é…çš„çœŸå®æ¡†ï¼ˆéèƒŒæ™¯ç±»ï¼‰ä¸ºFN
                for gt_idx in range(len(all_tgt_boxes)):
                    if not gt_matched[gt_idx] and all_tgt_labels[gt_idx].item() not in background_classes:
                        total_false_negative += 1

                # ===== æ ·æœ¬çº§åˆ†æ•°ï¼ˆä¸å®šä½å£å¾„ä¸€è‡´ï¼‰ï¼šå­˜åœ¨ä»»ä¸€åŒ¹é…æˆåŠŸçš„é¢„æµ‹æ¡†å³ä¸ºæ­£ï¼Œåˆ†æ•°å–åŒ¹é…æ¡†æœ€é«˜åˆ† =====
                matched_indices = [idx for idx,
                                   m in enumerate(pred_matched) if m]
                if len(matched_indices) > 0:
                    best_score = float(
                        max([all_pred_scores[idx].item() for idx in matched_indices]))
                else:
                    best_score = 0.0
                collected_sample_labels.append(1)
                collected_sample_scores.append(best_score)

                # ===== ğŸ”¥ ä¿®æ­£ï¼šæ”¶é›†åŒ¹é…æ¡†çš„åˆ†ç±»æŒ‡æ ‡æ•°æ® =====
                # æ”¶é›†æ‰€æœ‰IoUæ»¡è¶³é˜ˆå€¼çš„åŒ¹é…æ¡†çš„åˆ†ç±»æ•°æ®ï¼ˆåŒ…æ‹¬ç±»åˆ«æ­£ç¡®å’Œé”™è¯¯çš„ï¼‰
                if not localization_only:  # åªåœ¨éå®šä½ä»»åŠ¡æ¨¡å¼ä¸‹æ”¶é›†åˆ†ç±»æŒ‡æ ‡
                    for pred_idx in range(num_queries):
                        pred_label = all_pred_labels[pred_idx].item()
                        pred_score = all_pred_scores[pred_idx].item()

                        # æ”¶é›†æ‰€æœ‰IoUæ»¡è¶³é˜ˆå€¼çš„é¢„æµ‹æ¡†
                        if (pred_label not in background_classes and
                                pred_score >= EVAL_CONFIDENCE_THRESHOLD):

                            # æ£€æŸ¥æ˜¯å¦ä¸ä»»ä½•GTæ¡†åŒ¹é…ï¼ˆIoUæ»¡è¶³é˜ˆå€¼ï¼‰
                            best_iou = 0.0
                            best_gt_label = -1

                            for gt_idx in range(len(all_tgt_boxes)):
                                gt_label = all_tgt_labels[gt_idx]
                                if hasattr(gt_label, 'item'):
                                    gt_label = gt_label.item()
                                if gt_label not in background_classes:
                                    gt_box = all_tgt_boxes[gt_idx]
                                    pred_box = all_pred_boxes[pred_idx]
                                    iou = compute_1d_iou(
                                        pred_box.tolist(), gt_box.tolist())

                                    if iou >= IOU_THRESHOLD and iou > best_iou:
                                        best_iou = iou
                                        best_gt_label = gt_label

                            # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„GTæ¡†ï¼Œæ”¶é›†åˆ†ç±»æ•°æ®
                            if best_gt_label != -1:
                                image_pred_labels.append(pred_label)
                                image_pred_probs.append(
                                    pred_probs[pred_idx].tolist())
                                image_true_labels.append(best_gt_label)

                if binary_mode and not localization_only:
                    pos_probs_queries = (1.0 - pred_probs[:, detr_bg_class])
                    bg_probs_queries = pred_probs[:, detr_bg_class]
                    prob_vectors = torch.stack([pos_probs_queries, bg_probs_queries], dim=-1)
                    pred_labels_bin = (pos_probs_queries >= 0.5).long()
                    true_labels_bin = (true_labels != detr_bg_class).long()

                    collected_pred_probs_bin.extend(prob_vectors.tolist())
                    collected_pred_labels_bin.extend(pred_labels_bin.tolist())
                    collected_true_labels_bin.extend(true_labels_bin.tolist())

                # ===== å®šä½æ ‡ç­¾æ”¶é›†ï¼ˆåªæ”¶é›†æ­£æ ·æœ¬å›¾åƒï¼‰ =====
                # è·å–åºåˆ—é•¿åº¦ç”¨äºåå½’ä¸€åŒ–
                seq_len = targets[i].get('size', 128)
                if isinstance(seq_len, torch.Tensor):
                    if seq_len.numel() == 1:
                        seq_len = seq_len
                        if hasattr(seq_len, 'item'):
                            seq_len = seq_len.item()
                    else:
                        seq_len_val = seq_len[0]
                        if hasattr(seq_len_val, 'item'):
                            seq_len_val = seq_len_val.item()
                        seq_len = seq_len_val

                # åˆ›å»ºCDSçº§åˆ«çš„æ ‡ç­¾å’Œç½®ä¿¡åº¦
                cds_length = seq_len
                cds_true_labels = torch.zeros(
                    cds_length, dtype=torch.bool)  # çœŸå®CDSæ ‡ç­¾
                cds_pred_scores = torch.zeros(
                    cds_length, dtype=torch.float)  # é¢„æµ‹CDSç½®ä¿¡åº¦

                # 1. æ ‡è®°çœŸå®BGCåŒºåŸŸçš„CDSä½ç½®
                for gt_idx in range(len(all_tgt_boxes)):
                    gt_label = all_tgt_labels[gt_idx]
                    if hasattr(gt_label, 'item'):
                        gt_label = gt_label.item()
                    if gt_label not in background_classes:  # åªå¤„ç†éèƒŒæ™¯ç±»
                        gt_box = all_tgt_boxes[gt_idx]
                        # åå½’ä¸€åŒ–åæ ‡
                        start_pos = int(gt_box[0].item() * seq_len)
                        end_pos = int(gt_box[1].item() * seq_len)
                        # ç¡®ä¿ä½ç½®åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        start_pos = max(0, min(start_pos, cds_length - 1))
                        end_pos = max(start_pos, min(end_pos, cds_length))
                        # æ ‡è®°çœŸå®BGCåŒºåŸŸçš„CDSä¸ºTrue
                        cds_true_labels[start_pos:end_pos] = True

                # 2. è®¡ç®—é¢„æµ‹BGCåŒºåŸŸçš„CDSæ¦‚ç‡ï¼ˆåŸºäºæ¡†çš„è”åˆé€»è¾‘ï¼‰
                    base_prob = 0.0
                    cds_pred_scores.fill_(base_prob)
                    if EVAL_TEMPERATURE != 1.0:
                        pred_probs_full = (
                            all_pred_logits / EVAL_TEMPERATURE).softmax(-1)
                    else:
                        pred_probs_full = all_pred_logits.softmax(-1)
                    bg_index = background_classes[0]
                    pos_probs = 1.0 - pred_probs_full[:, bg_index]
                    sorted_pred_indices = torch.argsort(
                        pos_probs, descending=True)
                    all_boxes_abs = (all_pred_boxes *
                                     seq_len).clamp(0, seq_len).cpu()
                    keep_indices = nms_1d_greedy(
                        all_boxes_abs, pos_probs.cpu(), NMS_IOU_THRESHOLD)
                    keep_set = set(keep_indices)
                    for pred_idx in sorted_pred_indices:
                        if pred_idx.item() not in keep_set:
                            continue
                        pred_score = pos_probs[pred_idx]
                        if hasattr(pred_score, 'item'):
                            pred_score = pred_score.item()
                        if pred_score >= EVAL_CONFIDENCE_THRESHOLD:
                            pred_box = all_pred_boxes[pred_idx]
                            start_pos = int(pred_box[0].item() * seq_len)
                            end_pos = int(pred_box[1].item() * seq_len)
                            start_pos = max(0, min(start_pos, cds_length - 1))
                            end_pos = max(start_pos, min(end_pos, cds_length))
                            center = (start_pos + end_pos) / 2
                            box_length = max(1, end_pos - start_pos)
                            if end_pos > start_pos:
                                positions = torch.arange(start_pos, end_pos)
                                distances = (positions - center).abs().float()
                                sigma = max(1.0, (box_length / 2.0) + 3.0)
                                distance_weight = torch.exp(
                                    - (distances ** 2) / (2.0 * (sigma ** 2)))
                                pred_probs = float(
                                    pred_score) * distance_weight
                                old = cds_pred_scores[positions].float()
                                cds_pred_scores[positions] = 1.0 - \
                                    (1.0 - old) * (1.0 - pred_probs)

                # 3. æ”¶é›†CDSçº§åˆ«çš„æ ‡ç­¾å’Œç½®ä¿¡åº¦
                for cds_pos in range(cds_length):
                    image_loc_labels.append(
                        int(cds_true_labels[cds_pos].item()))
                    image_loc_scores.append(cds_pred_scores[cds_pos].item())

                # å…¨å±€æ”¶é›†
                collected_pred_labels.extend(image_pred_labels)
                collected_true_labels.extend(image_true_labels)
                collected_pred_probs.extend(image_pred_probs)
                collected_true_local.extend(image_loc_labels)
                collected_pred_local.extend(image_loc_scores)
            else:
                # ===== è´Ÿæ ·æœ¬å›¾åƒå¤„ç†ï¼ˆä¿®æ”¹FPè®¡ç®—é€»è¾‘ï¼‰ =====
                # ğŸ”¥ ä¿®æ”¹ï¼šè´Ÿæ ·æœ¬ä¸­åªè¦æœ‰é¢„æµ‹æ­£æ ·æœ¬BGCç±»åˆ«å°±ç®—ä¸€ä¸ªFP
                has_positive_prediction = False  # æ ‡è®°æ˜¯å¦æœ‰æ­£æ ·æœ¬é¢„æµ‹

                for pred_idx in range(len(all_pred_boxes)):
                    pred_label = all_pred_labels[pred_idx]
                    if hasattr(pred_label, 'item'):
                        pred_label = pred_label.item()
                    pred_score = all_pred_scores[pred_idx]
                    if hasattr(pred_score, 'item'):
                        pred_score = pred_score.item()

                    # æ£€æŸ¥æ˜¯å¦æœ‰é¢„æµ‹æ­£æ ·æœ¬BGCç±»åˆ«ï¼ˆåŠ å…¥ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ï¼‰
                    if (pred_label not in background_classes and
                            pred_score >= EVAL_CONFIDENCE_THRESHOLD):
                        has_positive_prediction = True
                        break  # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†ï¼Œä¸éœ€è¦ç»§ç»­æ£€æŸ¥

                # æ ·æœ¬çº§åˆ†æ•°ï¼šæ— åŒ¹é…ï¼Œè®°ä¸º0
                collected_sample_labels.append(0)
                collected_sample_scores.append(0.0)

                # æ¯ä¸ªè´Ÿæ ·æœ¬æœ€å¤šè´¡çŒ®1ä¸ªFP
                if has_positive_prediction:
                    total_false_positive += 1
                    fp_from_negative_samples += 1

                if binary_mode and not localization_only:
                    pred_probs = all_pred_logits.softmax(-1)
                    pos_probs_queries = (1.0 - pred_probs[:, detr_bg_class])
                    bg_probs_queries = pred_probs[:, detr_bg_class]
                    prob_vectors = torch.stack([pos_probs_queries, bg_probs_queries], dim=-1)
                    pred_labels_bin = (pos_probs_queries >= 0.5).long()
                    true_labels_bin = torch.zeros_like(pred_labels_bin)

                    collected_pred_probs_bin.extend(prob_vectors.tolist())
                    collected_pred_labels_bin.extend(pred_labels_bin.tolist())
                    collected_true_labels_bin.extend(true_labels_bin.tolist())

            image_id += 1

    # ===== è®¡ç®—æ¯ä¸ªç±»åˆ«çš„APï¼ˆè´ªå¿ƒåŒ¹é…ï¼‰ =====
    class_aps = {}
    class_precisions = {}
    class_recalls = {}

    for class_id in all_predictions.keys():
        if class_id in background_classes:
            continue

        # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰é¢„æµ‹æ¡†ï¼ŒæŒ‰ç½®ä¿¡åº¦é™åºæ’åº
        class_predictions = all_predictions[class_id]
        class_predictions.sort(key=lambda x: x[0], reverse=True)  # æŒ‰scoreé™åºæ’åº

        # è·å–è¯¥ç±»åˆ«çš„çœŸå®æ¡†æ€»æ•°
        total_gt = all_targets[class_id]

        if total_gt == 0:
            continue

        print(f"\nç±»åˆ« {class_id}: é¢„æµ‹æ¡†æ•°={len(class_predictions)}, çœŸå®æ¡†æ•°={total_gt}")

        # è·å–è¯¥ç±»åˆ«çš„çœŸå®æ¡†ä¿¡æ¯
        gt_boxes_by_image = all_gt_boxes_by_image[class_id]

        # æ‰§è¡Œè´ªå¿ƒåŒ¹é…ï¼ˆæ ‡å‡†mAPè®¡ç®—æµç¨‹ï¼‰
        tp = []
        fp = []
        scores = []

        # ä¸ºæ¯ä¸ªå›¾åƒåˆ›å»ºçœŸå®æ¡†åŒ¹é…çŠ¶æ€
        gt_matched_by_image = {}
        for img_id, gt_boxes in gt_boxes_by_image.items():
            gt_matched_by_image[img_id] = [False] * len(gt_boxes)

        # æŒ‰ç½®ä¿¡åº¦ä»é«˜åˆ°ä½å¤„ç†æ¯ä¸ªé¢„æµ‹æ¡†ï¼ˆæ ‡å‡†mAPï¼šä¸ä½¿ç”¨ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ï¼‰
        for score, pred_box, img_id, _ in class_predictions:
            scores.append(score)

            # åœ¨å¯¹åº”å›¾åƒä¸­å¯»æ‰¾æœ€ä½³åŒ¹é…çš„çœŸå®æ¡†
            # æ³¨æ„ï¼šç”±äºæ˜¯æŒ‰ç±»åˆ«åˆ†åˆ«è®¡ç®—ï¼Œgt_boxes_by_image[class_id]ä¸­çš„æ‰€æœ‰GTæ¡†
            # éƒ½å·²ç»æ˜¯å½“å‰class_idç±»åˆ«ï¼Œä¿è¯äº†ä¸¥æ ¼çš„ç±»åˆ«ä¸€è‡´æ€§åŒ¹é…
            best_iou = 0.0
            best_gt_idx = -1

            if img_id in gt_boxes_by_image:
                for gt_idx, gt_box in enumerate(gt_boxes_by_image[img_id]):
                    if gt_matched_by_image[img_id][gt_idx]:
                        continue

                    # è®¡ç®—IoUï¼ˆç±»åˆ«å·²ç»é€šè¿‡æ•°æ®ç»“æ„ä¿è¯ä¸€è‡´ï¼‰
                    iou = compute_1d_iou(pred_box.tolist(), gt_box.tolist())
                    if iou > best_iou:
                        best_iou = iou
                        best_gt_idx = gt_idx

            # ä½¿ç”¨IoUé˜ˆå€¼åˆ¤æ–­TP/FPï¼ˆè¿™é‡Œæ˜¯mAPæ ‡å‡†ä¸­çš„å”¯ä¸€é˜ˆå€¼ï¼‰
            if best_iou >= IOU_THRESHOLD and best_gt_idx != -1:
                tp.append(1)  # True Positive: ç›¸åŒç±»åˆ«ä¸”IoUâ‰¥é˜ˆå€¼
                fp.append(0)
                gt_matched_by_image[img_id][best_gt_idx] = True
            else:
                tp.append(0)
                fp.append(1)  # False Positive: æœªæ‰¾åˆ°åŒ¹é…æˆ–IoU<é˜ˆå€¼

        # è®¡ç®—precisionå’Œrecall
        tp = np.array(tp)
        fp = np.array(fp)
        scores = np.array(scores)

        # ç´¯ç§¯è®¡ç®—
        tp_cumsum = np.cumsum(tp)
        fp_cumsum = np.cumsum(fp)

        # è®¡ç®—precisionå’Œrecall
        precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)
        recalls = tp_cumsum / (total_gt + 1e-6)

        # è®¡ç®—AP (ä½¿ç”¨11ç‚¹æ’å€¼)
        ap = 0.0
        for t in np.linspace(0, 1, 11):
            if np.sum(recalls >= t) == 0:
                p = 0
            else:
                p = np.max(precisions[recalls >= t])
            ap += p / 11

        class_aps[class_id] = ap
        class_precisions[class_id] = precisions[-1] if len(
            precisions) > 0 else 0
        class_recalls[class_id] = recalls[-1] if len(recalls) > 0 else 0

        class_name = class_mapping.get(
            class_id, f"ç±»åˆ«{class_id}") if class_mapping else f"ç±»åˆ«{class_id}"
        print(
            f"  {class_name}: AP={ap:.4f}, P={precisions[-1]:.4f}, R={recalls[-1]:.4f}")

    # è®¡ç®—mAP
    mean_ap = np.mean(list(class_aps.values())) if class_aps else 0.0
    mean_precision = np.mean(
        list(class_precisions.values())) if class_precisions else 0.0
    mean_recall = np.mean(list(class_recalls.values())
                          ) if class_recalls else 0.0
    map_f1 = 2 * (mean_precision * mean_recall) / (mean_precision + mean_recall) if (
        mean_precision + mean_recall) > 0 else 0.0

    print(
        f"\næ€»ä½“mAPç»“æœ: mAP={mean_ap:.4f}, mP={mean_precision:.4f}, mR={mean_recall:.4f}, F1={map_f1:.4f}")

    # è®¡ç®—ä½ç½®ç²¾åº¦è¯„ä¼°æŒ‡æ ‡
    precision = total_correct_boxes / (total_correct_boxes + total_false_positive) if (
        total_correct_boxes + total_false_positive) > 0 else 0
    recall = total_correct_boxes / (total_correct_boxes + total_false_negative) if (
        total_correct_boxes + total_false_negative) > 0 else 0
    f1 = 2 * (precision * recall) / (precision +
                                     recall) if (precision + recall) > 0 else 0

    # æ‰“å°å…¨å±€åˆ†å¸ƒç»Ÿè®¡
    print("\n===== å…¨å±€åˆ†å¸ƒç»Ÿè®¡ =====")
    print(f"æ­£æ ·æœ¬æ•°é‡: {num_positive_samples}")

    # 1. IoUåˆ†å¸ƒåˆ†æ
    if len(iou_distribution) > 0:
        ious = np.array(iou_distribution, dtype=np.float32)  # æ˜ç¡®æŒ‡å®šæ•°æ®ç±»å‹
        print(f"\nIoUåˆ†å¸ƒ (å…±{len(ious)}ä¸ªé¢„æµ‹æ¡†):")
        print(f"  - å¹³å‡IoU: {ious.mean():.4f}")
        print(
            f"  - IoU < 0.3: {(ious < 0.3).sum()} ({(ious < 0.3).sum() / len(ious) * 100:.1f}%)")
        print(
            f"  - 0.3 â‰¤ IoU < 0.5: {((ious >= 0.3) & (ious < 0.5)).sum()} ({((ious >= 0.3) & (ious < 0.5)).sum() / len(ious) * 100:.1f}%)")
        print(
            f"  - IoU â‰¥ 0.5: {(ious >= 0.5).sum()} ({(ious >= 0.5).sum() / len(ious) * 100:.1f}%)")
    else:
        print("\næ— IoUæ•°æ®å¯ç»Ÿè®¡ï¼ˆå¯èƒ½æ²¡æœ‰æ­£æ ·æœ¬ï¼‰")

    # 2. é¢„æµ‹ç±»åˆ«åˆ†å¸ƒåˆ†æ
    if bg_pred_count + non_bg_pred_count > 0:
        total_pred = bg_pred_count + non_bg_pred_count
        print(f"\né¢„æµ‹ç±»åˆ«åˆ†å¸ƒ (å…±{total_pred}ä¸ªé¢„æµ‹æ¡†):")
        print(
            f"  - èƒŒæ™¯ç±»é¢„æµ‹: {bg_pred_count} ({bg_pred_count / total_pred * 100:.1f}%)")
        print(
            f"  - éèƒŒæ™¯ç±»é¢„æµ‹: {non_bg_pred_count} ({non_bg_pred_count / total_pred * 100:.1f}%)")

        print("\né¢„æµ‹å„ç±»åˆ«æ•°é‡:")
        for cls, count in sorted(class_distribution.items()):
            if cls in background_classes:
                cls_name = "èƒŒæ™¯(no-object)"
            elif class_mapping and cls in class_mapping:
                cls_name = f"{class_mapping[cls]}(ç´¢å¼•{cls})"
            else:
                cls_name = f"ç±»åˆ«{cls}"
            print(f"  - {cls_name}: {count}ä¸ª")
    else:
        print("\næ— é¢„æµ‹ç±»åˆ«åˆ†å¸ƒæ•°æ®å¯ç»Ÿè®¡")

    # 3. çœŸå®ç±»åˆ«åˆ†å¸ƒåˆ†æ
    if gt_bg_count + gt_non_bg_count > 0:
        total_gt = gt_bg_count + gt_non_bg_count
        print(f"\nçœŸå®ç±»åˆ«åˆ†å¸ƒ (å…±{total_gt}ä¸ªçœŸå®æ¡†):")
        print(
            f"  - èƒŒæ™¯ç±»çœŸå®æ¡†: {gt_bg_count} ({gt_bg_count / total_gt * 100:.1f}%)")
        print(
            f"  - éèƒŒæ™¯ç±»çœŸå®æ¡†: {gt_non_bg_count} ({gt_non_bg_count / total_gt * 100:.1f}%)")

        print("\nçœŸå®å„ç±»åˆ«æ•°é‡:")
        for cls, count in sorted(gt_class_distribution.items()):
            if cls in background_classes:
                cls_name = "èƒŒæ™¯(no-object)"
            elif class_mapping and cls in class_mapping:
                cls_name = f"{class_mapping[cls]}(ç´¢å¼•{cls})"
            else:
                cls_name = f"ç±»åˆ«{cls}"
            print(f"  - {cls_name}: {count}ä¸ª")
    else:
        print("\næ— çœŸå®ç±»åˆ«åˆ†å¸ƒæ•°æ®å¯ç»Ÿè®¡")

    print("=" * 50)

    # ===== ç½®ä¿¡åº¦è¿‡æ»¤æ•ˆæœåˆ†æ =====
    print(f"\nğŸ¯ ç½®ä¿¡åº¦è¿‡æ»¤æ•ˆæœåˆ†æ (é˜ˆå€¼={EVAL_CONFIDENCE_THRESHOLD}):")
    filtered_pred_ratio = (
        non_bg_pred_count - total_predicted_boxes) / non_bg_pred_count if non_bg_pred_count > 0 else 0
    print(f"  â€¢ åŸå§‹éèƒŒæ™¯é¢„æµ‹æ¡†: {non_bg_pred_count:,}ä¸ª")
    print(f"  â€¢ é€šè¿‡ç½®ä¿¡åº¦è¿‡æ»¤: {total_predicted_boxes:,}ä¸ª")
    print(f"  â€¢ è¢«è¿‡æ»¤æ‰çš„é¢„æµ‹æ¡†: {non_bg_pred_count - total_predicted_boxes:,}ä¸ª")
    print(f"  â€¢ è¿‡æ»¤æ¯”ä¾‹: {filtered_pred_ratio:.1%}")

    if total_predicted_boxes > 0:
        filtered_precision = total_correct_boxes / total_predicted_boxes
        print(f"  â€¢ è¿‡æ»¤åç²¾ç¡®ç‡: {filtered_precision:.1%}")
        print(f"  â€¢ ç²¾ç¡®ç‡æå‡æ•ˆæœ: æ˜¾è‘—å‡å°‘äº†ä½è´¨é‡é¢„æµ‹æ¡†")

    # ===== è¯¦ç»†ç±»åˆ«åŒ¹é…åˆ†ææŠ¥å‘Š =====
    print(f"\nğŸ” è¯¦ç»†ç±»åˆ«åŒ¹é…åˆ†ææŠ¥å‘Š (ç½®ä¿¡åº¦â‰¥{EVAL_CONFIDENCE_THRESHOLD}):")
    print(f"{'ç±»åˆ«':<12} {'é¢„æµ‹æ¡†':<8} {'çœŸå®æ¡†':<8} {'æˆåŠŸåŒ¹é…':<10} {'åŒ¹é…ç‡':<10} {'é«˜IoUå¤±é…':<12} {'ä½IoU':<8}")
    print("-" * 80)

    total_pred_analyzed = 0
    total_gt_analyzed = 0
    total_matched_analyzed = 0
    total_high_iou_mismatch = 0
    total_low_iou = 0

    for class_id in sorted(set(list(class_match_analysis.keys()) + list(gt_class_distribution.keys()))):
        if class_id in background_classes:
            continue

        analysis = class_match_analysis[class_id]
        pred_count = analysis['pred_count']
        gt_count = analysis['gt_count']
        matched_count = analysis['matched_count']
        high_iou_count = analysis['high_iou_count']
        low_iou_count = analysis['low_iou_count']

        match_rate = matched_count / pred_count if pred_count > 0 else 0

        class_name = class_mapping.get(
            class_id, f"ç±»åˆ«{class_id}") if class_mapping else f"ç±»åˆ«{class_id}"
        print(
            f"{class_name:<12} {pred_count:<8} {gt_count:<8} {matched_count:<10} {match_rate:<10.3f} {high_iou_count:<12} {low_iou_count:<8}")

        total_pred_analyzed += pred_count
        total_gt_analyzed += gt_count
        total_matched_analyzed += matched_count
        total_high_iou_mismatch += high_iou_count
        total_low_iou += low_iou_count

    print("-" * 80)
    overall_match_rate = total_matched_analyzed / \
        total_pred_analyzed if total_pred_analyzed > 0 else 0
    print(
        f"{'æ€»è®¡':<12} {total_pred_analyzed:<8} {total_gt_analyzed:<8} {total_matched_analyzed:<10} {overall_match_rate:<10.3f} {total_high_iou_mismatch:<12} {total_low_iou:<8}")

    print(f"\nğŸ“Š å…³é”®å‘ç°:")
    print(f"  â€¢ é«˜ç½®ä¿¡åº¦é¢„æµ‹æ¡†: {total_pred_analyzed:,}")
    print(f"  â€¢ æˆåŠŸåŒ¹é…: {total_matched_analyzed} ({overall_match_rate:.1%})")

    # é¿å…é™¤é›¶é”™è¯¯
    if total_pred_analyzed > 0:
        print(
            f"  â€¢ é«˜IoUä½†ç±»åˆ«ä¸åŒ¹é…: {total_high_iou_mismatch} ({total_high_iou_mismatch / total_pred_analyzed:.1%})")
        print(
            f"  â€¢ ä½IoU: {total_low_iou} ({total_low_iou / total_pred_analyzed:.1%})")
    else:
        print(f"  â€¢ é«˜IoUä½†ç±»åˆ«ä¸åŒ¹é…: {total_high_iou_mismatch} (0.0%)")
        print(f"  â€¢ ä½IoU: {total_low_iou} (0.0%)")

    # åˆ†ç±»F1/AUC
    debug_info = {}  # ç”¨äºæ”¶é›†DEBUGä¿¡æ¯
    # ç»Ÿä¸€æ ‡ç­¾å˜é‡åï¼Œç¡®ä¿åç»­æŒ‡æ ‡è®¡ç®—ä½¿ç”¨æ­£ç¡®æ•°æ®ï¼ˆåªç”¨è‡ªå®šä¹‰æ”¶é›†çš„å˜é‡ï¼‰
    if binary_mode and not localization_only:
        all_true_labels = collected_true_labels_bin
        all_pred_labels = collected_pred_labels_bin
        all_pred_probs = collected_pred_probs_bin
    else:
        all_true_labels = collected_true_labels
        all_pred_labels = collected_pred_labels
        all_pred_probs = collected_pred_probs
    all_true_local = collected_true_local
    all_pred_local = collected_pred_local

    # è°ƒè¯•ä¿¡æ¯æ‰“å°
    print(f"\n===== è°ƒè¯•ä¿¡æ¯ =====")
    print(f"æ­£æ ·æœ¬å›¾åƒæ•°: {debug_positive_images}")
    print(f"è´Ÿæ ·æœ¬å›¾åƒæ•°: {debug_negative_images}")
    print(f"æ€»å›¾åƒæ•°: {debug_positive_images + debug_negative_images}")
    print(f"å®é™…æ”¶é›†çš„é¢„æµ‹æ¡†æ•°: {debug_pred_boxes_collected}")
    print(f"total_predicted_boxes: {total_predicted_boxes}")
    print(f"éèƒŒæ™¯ç±»é¢„æµ‹æ¡†æ€»æ•°: {non_bg_pred_count}")
    print(f"èƒŒæ™¯ç±»ç´¢å¼•: {background_classes}")

    # åˆ†æé¢„æµ‹ç±»åˆ«åˆ†å¸ƒ
    print(f"\n===== é¢„æµ‹ç±»åˆ«åˆ†å¸ƒåˆ†æ =====")
    total_predictions = sum(class_distribution.values())
    print(f"æ‰€æœ‰é¢„æµ‹æ¡†æ€»æ•°: {total_predictions}")
    print("å„ç±»åˆ«é¢„æµ‹å æ¯”:")
    for cls in sorted(class_distribution.keys()):
        count = class_distribution[cls]
        percentage = count / total_predictions * 100 if total_predictions > 0 else 0
        cls_name = f"èƒŒæ™¯(no-object)" if cls in background_classes else f"ç±»åˆ«{cls}"
        print(f"  {cls_name}: {count}ä¸ª ({percentage:.1f}%)")

    # åˆ†æçœŸå®ç±»åˆ«åˆ†å¸ƒ
    print(f"\n===== çœŸå®ç±»åˆ«åˆ†å¸ƒåˆ†æ =====")
    total_gt = sum(gt_class_distribution.values())
    print(f"æ‰€æœ‰çœŸå®æ¡†æ€»æ•°: {total_gt}")
    print("å„ç±»åˆ«çœŸå®å æ¯”:")
    for cls in sorted(gt_class_distribution.keys()):
        count = gt_class_distribution[cls]
        percentage = count / total_gt * 100 if total_gt > 0 else 0
        cls_name = f"èƒŒæ™¯(no-object)" if cls in background_classes else f"ç±»åˆ«{cls}"
        print(f"  {cls_name}: {count}ä¸ª ({percentage:.1f}%)")

    print("=" * 25)

    # åªåœ¨éå®šä½ä»»åŠ¡æ¨¡å¼ä¸‹è®¡ç®—åˆ†ç±»æŒ‡æ ‡
    if not localization_only:
        try:
            # æŠ‘åˆ¶NumPyè­¦å‘Š
            import warnings
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", category=RuntimeWarning)

                # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„F1åˆ†æ•°
                class_f1_macro = f1_score(
                    all_true_labels, all_pred_labels, average='macro', zero_division=0)
                class_f1_weighted = f1_score(
                    all_true_labels, all_pred_labels, average='weighted', zero_division=0)
                class_f1_per_class = f1_score(
                    all_true_labels, all_pred_labels, average=None, zero_division=0).tolist()

                # æ£€æŸ¥all_pred_probsçš„shape
                all_pred_probs_np = np.array(all_pred_probs)
                if all_pred_probs_np.ndim == 2 and all_pred_probs_np.shape[0] == len(all_true_labels):
                    # æ£€æŸ¥æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°
                    class_counts = np.bincount(all_true_labels)
                    valid_classes = np.where(class_counts > 0)[0]

                    if len(valid_classes) > 1:
                        # ç¡®ä¿æ ‡ç­¾æ˜¯one-hotå½¢å¼
                        y_true_one_hot = np.eye(all_pred_probs_np.shape[1])[
                            all_true_labels]
                        # åªä½¿ç”¨æœ‰æ ·æœ¬çš„ç±»åˆ«è®¡ç®—AUC
                        try:
                            class_auc = roc_auc_score(
                                y_true_one_hot[:, valid_classes],
                                all_pred_probs_np[:, valid_classes],
                                average='macro',
                                multi_class='ovr'
                            )
                            # print(f"[DEBUG] åˆ†ç±»AUC: {class_auc:.4f}")
                        except Exception as auc_error:
                            # print(f"[DEBUG] AUCè®¡ç®—é”™è¯¯: {str(auc_error)}")
                            class_auc = 0.0
                    else:
                        print(
                            f'[DEBUG] è­¦å‘Š: åªæœ‰ä¸€ä¸ªç±»åˆ«({valid_classes[0]})ï¼Œæ— æ³•è®¡ç®—AUC')
                        debug_info['auc_warning'] = f'åªæœ‰ä¸€ä¸ªç±»åˆ«({valid_classes[0]})ï¼Œæ— æ³•è®¡ç®—AUC'
                        class_auc = 0.0
                else:
                    print(
                        f'[DEBUG] è­¦å‘Š: all_pred_probs shapeä¸æ­£ç¡®: {all_pred_probs_np.shape}, true_labelæ•°: {len(all_true_labels)}')
                    debug_info[
                        'shape_warning'] = f'all_pred_probs shapeä¸æ­£ç¡®: {all_pred_probs_np.shape}, true_labelæ•°: {len(all_true_labels)}'
                    class_auc = 0.0
                class_confusion = confusion_matrix(
                    all_true_labels, all_pred_labels).tolist()
        except Exception as e:
            debug_info['calculation_error'] = str(e)
            class_f1_macro = 0.0
            class_f1_weighted = 0.0
            class_f1_per_class = []
            class_auc = 0.0
            class_confusion = []
    else:
        # å®šä½ä»»åŠ¡æ¨¡å¼ï¼šè®¾ç½®é»˜è®¤å€¼
        class_f1_macro = 0.0
        class_f1_weighted = 0.0
        class_f1_per_class = []
        class_auc = 0.0
        class_confusion = []
        print("[DEBUG] å®šä½ä»»åŠ¡æ¨¡å¼ï¼šè·³è¿‡åˆ†ç±»æŒ‡æ ‡è®¡ç®—")

    # ===== æ ·æœ¬çº§ï¼ˆäºŒåˆ†ç±»ï¼‰AUC/F1 =====
    try:
        if len(collected_sample_labels) == len(collected_sample_scores) and len(collected_sample_labels) > 0:
            # é€‰æ‹©é˜ˆå€¼0.5è®¡ç®—æ ·æœ¬çº§F1ï¼›AUCä½¿ç”¨è¿ç»­åˆ†æ•°
            sample_pred_labels = [
                1 if s >= 0.5 else 0 for s in collected_sample_scores]
            sample_f1 = f1_score(
                collected_sample_labels, sample_pred_labels, average='binary', zero_division=0)
            if len(set(collected_sample_labels)) > 1:
                sample_auc = roc_auc_score(
                    collected_sample_labels, collected_sample_scores)
            else:
                sample_auc = 0.5
        else:
            sample_f1, sample_auc = 0.0, 0.5
    except Exception:
        sample_f1, sample_auc = 0.0, 0.5

    # ===== ä½ç½®F1/AUCè®¡ç®—ï¼ˆCDSçº§åˆ«ï¼‰ =====
    try:
        # è®¡ç®—ä½ç½®F1åˆ†æ•°
        if len(all_true_local) > 0 and len(all_pred_local) > 0:
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            print(f"CDSçº§åˆ«å®šä½è¯„ä¼°:")
            print(f"  æ€»CDSæ•°: {len(all_true_local)}")
            print(f"  çœŸå®BGCåŒºåŸŸCDSæ•°: {sum(all_true_local)}")
            print(
                f"  é¢„æµ‹BGCåŒºåŸŸCDSæ•°: {sum([1 for x in all_pred_local if x > 0.5])}")
            print(
                f"  é¢„æµ‹æ ‡ç­¾åˆ†å¸ƒ: 0={sum([1 for x in all_pred_local if x < 0.5])}, 1={sum([1 for x in all_pred_local if x > 0.5])}")

            # ğŸ”§ ä¿®å¤ï¼šä¸ºF1è®¡ç®—åˆ›å»ºäºŒè¿›åˆ¶é¢„æµ‹æ ‡ç­¾
            loc_pred_labels = [1 if prob >
                               0.5 else 0 for prob in all_pred_local]

            # è®¡ç®—CDSçº§åˆ«çš„TPã€FPã€FN
            cds_tp = sum(1 for pred, true in zip(loc_pred_labels,
                         all_true_local) if pred == 1 and true == 1)
            cds_fp = sum(1 for pred, true in zip(loc_pred_labels,
                         all_true_local) if pred == 1 and true == 0)
            cds_fn = sum(1 for pred, true in zip(loc_pred_labels,
                         all_true_local) if pred == 0 and true == 1)

            # è®¡ç®—CDSçº§åˆ«çš„ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1
            cds_precision = cds_tp / \
                (cds_tp + cds_fp) if (cds_tp + cds_fp) > 0 else 0
            cds_recall = cds_tp / \
                (cds_tp + cds_fn) if (cds_tp + cds_fn) > 0 else 0
            loc_f1 = f1_score(all_true_local, loc_pred_labels,
                              average='binary', zero_division=0)

            print(f"  CDSçº§åˆ«ç²¾ç¡®ç‡: {cds_precision:.4f}")
            print(f"  CDSçº§åˆ«å¬å›ç‡: {cds_recall:.4f}")
            print(f"  CDSçº§åˆ«F1: {loc_f1:.4f}")
            print(f"  CDSçº§åˆ«ç»Ÿè®¡: TP={cds_tp}, FP={cds_fp}, FN={cds_fn}")

            # è®¡ç®—CDSçº§åˆ«AUCï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨è¿ç»­é¢„æµ‹å€¼ï¼‰
            if len(set(all_true_local)) > 1:  # ç¡®ä¿æœ‰æ­£è´Ÿæ ·æœ¬
                try:
                    # ç›´æ¥ä½¿ç”¨è¿ç»­é¢„æµ‹å€¼è®¡ç®—AUCï¼ˆä¸å†è½¬æ¢ä¸ºäºŒè¿›åˆ¶ï¼‰
                    # è¿™æ ·èƒ½æ›´å¥½åœ°åæ˜ é¢„æµ‹çš„è´¨é‡å’Œç½®ä¿¡åº¦
                    loc_auc = roc_auc_score(all_true_local, all_pred_local)
                    print(f"  CDSçº§åˆ«AUC: {loc_auc:.4f}")

                except Exception as e:
                    print(f"  [è­¦å‘Š] AUCè®¡ç®—å¤±è´¥: {e}")
                    loc_auc = 0.5  # é»˜è®¤å€¼
            else:
                loc_auc = 0.5  # åªæœ‰ä¸€ç§æ ‡ç­¾æ—¶è¿”å›é»˜è®¤å€¼
                print(f"  [è­¦å‘Š] åªæœ‰ä¸€ç§æ ‡ç­¾ï¼Œæ— æ³•è®¡ç®—æœ‰æ„ä¹‰çš„AUC (AUC={loc_auc:.4f})")
        else:
            loc_f1 = 0.0
            loc_auc = 0.0
            print(f"[DEBUG] ä½ç½®æŒ‡æ ‡è­¦å‘Š: æ²¡æœ‰æ”¶é›†åˆ°ä½ç½®æ•°æ®")
    except Exception as e:
        print(f"[DEBUG] ä½ç½®æŒ‡æ ‡è®¡ç®—é”™è¯¯: {e}")
        loc_f1 = 0.0
        loc_auc = 0.0

    # è®¡ç®—è¯„ä¼°æ—¶çš„åˆ†ç±»é”™è¯¯ç‡ï¼ˆä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„é€»è¾‘ï¼‰
    # è®­ç»ƒæ—¶ï¼šé€šè¿‡criterion(outputs, targets)è®¡ç®—class_error
    # éªŒè¯æ—¶ï¼šæˆ‘ä»¬ä¹Ÿä½¿ç”¨åŒæ ·çš„criterionæ¥è®¡ç®—class_error
    eval_class_error = 0.0

    # åªåœ¨éå®šä½ä»»åŠ¡æ¨¡å¼ä¸‹è®¡ç®—åˆ†ç±»é”™è¯¯ç‡
    if not localization_only:
        # æ”¶é›†æ‰€æœ‰æ‰¹æ¬¡çš„class_error
        total_class_error = 0.0
        total_batches = 0

        # é‡æ–°éå†æ•°æ®æ¥è®¡ç®—class_error
        model.eval()
        criterion.eval()

        for samples, targets in data_loader:
            samples = samples.to(device)
            targets = [{k: v.to(device) for k, v in t.items()}
                       for t in targets]

            outputs = model(samples)
            loss_dict = criterion(outputs, targets)

            if 'class_error' in loss_dict:
                total_class_error += loss_dict['class_error'].item()
                total_batches += 1

        if total_batches > 0:
            eval_class_error = total_class_error / total_batches
        else:
            eval_class_error = 100.0

        print(f"[DEBUG] ä½¿ç”¨è®­ç»ƒæ—¶ç›¸åŒé€»è¾‘è®¡ç®—çš„åˆ†ç±»é”™è¯¯ç‡: {eval_class_error:.2f}%")
    else:
        print(f"[DEBUG] å®šä½ä»»åŠ¡æ¨¡å¼ï¼šè·³è¿‡åˆ†ç±»é”™è¯¯ç‡è®¡ç®—")

    # å°†è¯„ä¼°æŒ‡æ ‡ä¿å­˜åˆ°JSONæ–‡ä»¶
    test_metrics = {
        'epoch': epoch,
        'mAP': mean_ap,
        'mPrecision': mean_precision,
        'mRecall': mean_recall,
        'mAP_F1': map_f1,
        'class_APs': class_aps,
        'sample_level': {
            'f1': sample_f1,
            'auc': sample_auc
        },
        'localization': {
            'f1': loc_f1,
            'auc': loc_auc
        },
        'correct_boxes': total_correct_boxes,
        'total_predicted_boxes': total_predicted_boxes,
        'total_target_boxes': total_target_boxes,
        'false_positive': total_false_positive,
        'false_negative': total_false_negative,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'loss': metric_logger.meters['loss'].global_avg,
        'debug_info': debug_info  # æ·»åŠ DEBUGä¿¡æ¯åˆ°JSON
    }

    # åªåœ¨éå®šä½ä»»åŠ¡æ¨¡å¼ä¸‹æ·»åŠ åˆ†ç±»æŒ‡æ ‡
    if not localization_only:
        test_metrics['classification'] = {
            'f1': class_f1_macro,
            'auc': class_auc
        }
        test_metrics['eval_class_error'] = eval_class_error  # ä½¿ç”¨è¯„ä¼°æ—¶çš„åˆ†ç±»é”™è¯¯ç‡

    output_dir = Path(log_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    if fold is not None:
        filename = f'val_metrics_fold_{fold}_epoch_{epoch}.json'
    else:
        filename = f'val_metrics_epoch_{epoch}.json'
    with open(output_dir / filename, 'w') as f:
        json.dump(test_metrics, f, indent=4, ensure_ascii=False)

    # åœ¨éªŒè¯å¾ªç¯ç»“æŸåï¼Œåªåœ¨rank 0è¿›ç¨‹æ‰“å°ä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯
    print(f"\néªŒè¯é›†æŒ‡æ ‡:")
    if localization_only:
        print(f"ğŸ¯ å®šä½ä»»åŠ¡æ¨¡å¼ - åªè®¡ç®—å®šä½æŒ‡æ ‡:")
        print(f"ä½ç½®F1: {loc_f1:.4f}, ä½ç½®AUC: {loc_auc:.4f}")
        print(
            f"mAP: {mean_ap:.4f}, mP: {mean_precision:.4f}, mR: {mean_recall:.4f}, mAP-F1: {map_f1:.4f}")
    else:
        print(
            f"åˆ†ç±»F1: {class_f1_macro:.4f}, åˆ†ç±»AUC: {class_auc:.4f} (åŸºäºIoUåŒ¹é…æ¡†)")
        print(f"åˆ†ç±»é”™è¯¯ç‡: {eval_class_error:.2f}% (åŸºäºåŒ¹é…æ¡†ï¼Œä¸è®­ç»ƒæ—¶ç›¸åŒ)")
        print(f"ä½ç½®F1: {loc_f1:.4f}, ä½ç½®AUC: {loc_auc:.4f}")
        print(
            f"mAP: {mean_ap:.4f}, mP: {mean_precision:.4f}, mR: {mean_recall:.4f}, mAP-F1: {map_f1:.4f}")
    print(f"\nè¯¦ç»†ç»Ÿè®¡:")
    print(f"æ­£ç¡®é¢„æµ‹æ¡†æ•°: {total_correct_boxes}")
    print(f"æ€»é¢„æµ‹æ¡†æ•°: {total_predicted_boxes}")
    print(f"æ€»ç›®æ ‡æ¡†æ•°: {total_target_boxes}")
    print(f"å‡é˜³æ€§æ•°é‡: {total_false_positive}")
    print(f"å‡é˜´æ€§æ•°é‡: {total_false_negative}")
    print(f"ç²¾ç¡®ç‡: {precision:.4f}, å¬å›ç‡: {recall:.4f}, F1åˆ†æ•°: {f1:.4f}")
    print(f"ä½ç½®æ•°æ®ç»Ÿè®¡: çœŸå®æ ‡ç­¾æ•°={len(all_true_local)}, é¢„æµ‹ç½®ä¿¡åº¦æ•°={len(all_pred_local)}")
    if len(all_true_local) > 0:
        print(
            f"ä½ç½®çœŸå®æ ‡ç­¾åˆ†å¸ƒ: 0={all_true_local.count(0)}, 1={all_true_local.count(1)}")
        print(
            f"ä½ç½®é¢„æµ‹ç½®ä¿¡åº¦èŒƒå›´: [{min(all_pred_local):.4f}, {max(all_pred_local):.4f}]")
        print(f"CDSçº§åˆ«ä½ç½®è¯„ä¼°: æ€»CDSæ•°={len(all_true_local)}")
        print(f"  - çœŸå®BGCåŒºåŸŸCDSæ•°: {all_true_local.count(1)}")
        print(f"  - éBGCåŒºåŸŸCDSæ•°: {all_true_local.count(0)}")
        print(
            f"  - BGCåŒºåŸŸè¦†ç›–ç‡: {all_true_local.count(1)/len(all_true_local)*100:.2f}%")
    print("Averaged stats:", metric_logger)

    # ğŸ”¥ æ–°å¢ï¼šCDSçº§åˆ«æŒ‡æ ‡
    cds_level_metrics = {
        'precision': cds_precision if 'cds_precision' in locals() else 0,
        'recall': cds_recall if 'cds_recall' in locals() else 0,
        'f1_score': loc_f1,
        'total_cds_positions': len(all_true_local) if len(all_true_local) > 0 else 0,
        'true_positive': cds_tp if 'cds_tp' in locals() else 0,
        'false_positive': cds_fp if 'cds_fp' in locals() else 0,
        'false_negative': cds_fn if 'cds_fn' in locals() else 0
    }

    stats = {k: meter.global_avg for k, meter in metric_logger.meters.items()}
    stats.update({
        'mAP': mean_ap,
        'mPrecision': mean_precision,
        'mRecall': mean_recall,
        'mAP_F1': map_f1,
        'sample_level_f1': sample_f1,
        'sample_level_auc': sample_auc,
        'localization_f1': loc_f1,
        'localization_auc': loc_auc,
        'correct_boxes': total_correct_boxes,
        'total_predicted_boxes': total_predicted_boxes,
        'total_target_boxes': total_target_boxes,
        'false_positive': total_false_positive,
        'false_negative': total_false_negative,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'cds_level_metrics': cds_level_metrics  # ğŸ”¥ æ–°å¢CDSçº§åˆ«æŒ‡æ ‡
    })

    # åªåœ¨éå®šä½ä»»åŠ¡æ¨¡å¼ä¸‹æ·»åŠ åˆ†ç±»æŒ‡æ ‡
    if not localization_only:
        stats.update({
            'classification_f1': class_f1_macro,
            'classification_auc': class_auc,
        })
    return stats


# åˆ†å¸ƒå¼æ ‡ç­¾èšåˆå‡½æ•°
def gather_all_labels(local_labels, device):
    """
    åˆ†å¸ƒå¼æ ‡ç­¾èšåˆå‡½æ•°

    Args:
        local_labels: æœ¬åœ°æ ‡ç­¾åˆ—è¡¨
        device: è®¡ç®—è®¾å¤‡

    Returns:
        list: å…¨å±€æ ‡ç­¾åˆ—è¡¨
    """
    import torch
    local_tensor = torch.tensor(local_labels, device=device, dtype=torch.int32)
    local_len = torch.tensor([len(local_labels)], device=device)
    world_size = torch.distributed.get_world_size(
    ) if torch.distributed.is_initialized() else 1
    if world_size == 1:
        return local_labels
    all_lens = [torch.zeros_like(local_len) for _ in range(world_size)]
    torch.distributed.all_gather(all_lens, local_len)
    max_len = max([l.item() for l in all_lens])
    if len(local_labels) < max_len:
        local_tensor = torch.cat([local_tensor, torch.zeros(
            max_len - len(local_labels), dtype=torch.int32, device=device)])
    all_labels = [torch.zeros(max_len, dtype=torch.int32, device=device)
                  for _ in range(world_size)]
    torch.distributed.all_gather(all_labels, local_tensor)
    result = []
    for t, l in zip(all_labels, all_lens):
        result.extend(t[:l].tolist())
    return result


# æ–°å¢ï¼šåˆ†å¸ƒå¼æ¦‚ç‡åˆ†å¸ƒèšåˆå‡½æ•°


def gather_all_probs(local_probs, device, num_classes):
    """
    åˆ†å¸ƒå¼æ¦‚ç‡åˆ†å¸ƒèšåˆå‡½æ•°

    Args:
        local_probs: æœ¬åœ°æ¦‚ç‡åˆ†å¸ƒåˆ—è¡¨
        device: è®¡ç®—è®¾å¤‡
        num_classes: ç±»åˆ«æ•°é‡

    Returns:
        list: å…¨å±€æ¦‚ç‡åˆ†å¸ƒåˆ—è¡¨
    """
    import torch
    import numpy as np
    local_probs = np.array(local_probs, dtype=np.float32)
    if local_probs.ndim == 1:
        # åªæœ‰ä¸€ä¸ªæ ·æœ¬æ—¶ shape å¯èƒ½æ˜¯ (num_classes,)
        local_probs = local_probs[None, :]
    if local_probs.shape[0] == 0:
        # æ²¡æœ‰æ ·æœ¬æ—¶ shape åº”ä¸º (0, num_classes)
        local_probs = np.zeros((0, num_classes), dtype=np.float32)
    local_tensor = torch.tensor(
        local_probs, device=device, dtype=torch.float32)
    local_len = torch.tensor([local_tensor.shape[0]], device=device)
    world_size = torch.distributed.get_world_size(
    ) if torch.distributed.is_initialized() else 1
    if world_size == 1:
        return local_probs.tolist()
    all_lens = [torch.zeros_like(local_len) for _ in range(world_size)]
    torch.distributed.all_gather(all_lens, local_len)
    max_len = max([l.item() for l in all_lens])
    # è¡¥é›¶åˆ°æœ€å¤§é•¿åº¦
    if local_tensor.shape[0] < max_len:
        pad = torch.zeros(
            (max_len - local_tensor.shape[0], num_classes), dtype=torch.float32, device=device)
        local_tensor = torch.cat([local_tensor, pad], dim=0)
    all_tensors = [torch.zeros_like(local_tensor) for _ in range(world_size)]
    torch.distributed.all_gather(all_tensors, local_tensor)
    # æˆªæ–­è¡¥é›¶éƒ¨åˆ†
    all_probs = []
    for t, l in zip(all_tensors, all_lens):
        all_probs.append(t[:l.item()].cpu().numpy())
    all_probs = np.concatenate(all_probs, axis=0)
    return all_probs.tolist()
